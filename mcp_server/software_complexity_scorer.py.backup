import os
import json
import math
from typing import Dict, List, Any
from pathlib import Path
from urllib.parse import urlparse
import logging
try:
    import requests  # optional; only needed for remote map fetch
except ImportError:  # graceful degradation if requests isn't installed
    requests = None

import joblib
import numpy as np


class SoftwareComplexityScorer:
    """
    Software-only complexity scorer.

    This scorer does NOT do online search or cross-domain profession mapping.
    It strictly focuses on software/computer requirements and returns an error
    for non-software prompts based on a trained classifier.
    """

    def __init__(self, model_dir: str | None = None):
        if model_dir is None:
            model_dir = os.path.join(os.path.dirname(__file__), '..', 'models', 'software')
        self.model_dir = os.path.abspath(model_dir)
        self._load_models()

        # Load external tool mapping (not hard-coded) with robust fallbacks.
        # Precedence:
        #  1. SOFTWARE_TOOLS_MAP_PATH (local JSON file)
        #  2. SOFTWARE_TOOLS_MAP_URL  (remote JSON via HTTP GET)
        #  3. config/tech_tools_map.json (repo default)
        #  4. Built-in DEFAULT_TECH_TOOLS_MAP constant
        self.tech_tools_map: Dict[str, List[str]] = self._load_tools_map()

    @staticmethod
    def _default_tools_map() -> Dict[str, List[str]]:
        return {
            'react': ['Vite or Next.js', 'ESLint + Prettier', 'Jest/RTL', 'Tailwind or MUI'],
            'nextjs': ['Next.js', 'ESLint + Prettier', 'Jest/RTL', 'Tailwind or MUI'],
            'vue': ['Vite', 'ESLint + Prettier', 'Vitest', 'Pinia'],
            'angular': ['Angular CLI', 'ESLint', 'Jasmine/Karma'],
            'node': ['Express/Fastify', 'Jest', 'ESLint', 'Docker'],
            'python_fastapi': ['FastAPI', 'Uvicorn', 'PyTest', 'Docker'],
            'python_django': ['Django', 'PyTest', 'Black', 'Docker'],
            'flask': ['Flask', 'PyTest', 'Black', 'Docker'],
            'rails': ['Rails', 'RSpec', 'Rubocop', 'Docker'],
            'postgres': ['PostgreSQL', 'SQLAlchemy/Prisma/TypeORM', 'pgAdmin'],
            'mysql': ['MySQL', 'ORM (SQLAlchemy/Prisma)', 'Adminer'],
            'mongodb': ['MongoDB Atlas', 'Mongoose/Motor'],
            'redis': ['Redis', 'RedisInsight'],
            'auth': ['OAuth2/OIDC (Auth0/Clerk)', 'JWT'],
            'payments': ['Stripe SDK', 'Stripe CLI'],
            'devops': ['GitHub Actions', 'Docker', 'Kubernetes (optional)'],
            'ai_llm': ['OpenAI/Anthropic SDK', 'LangChain/LlamaIndex'],
            'testing': ['PyTest/Jest/Playwright'],
            'android': ['Android Studio', 'Gradle', 'JUnit', 'Jetpack'],
            'ios': ['Xcode', 'Swift Package Manager', 'XCTest'],
            'flutter': ['Flutter SDK', 'Dart DevTools', 'Widget Tests'],
            'react_native': ['React Native CLI', 'Metro', 'Jest', 'ESLint'],
        }

    def _load_tools_map(self) -> Dict[str, List[str]]:
        """Load technology -> tools mapping from file, URL or fallback.

        Returns a dict even on failure; logs warnings instead of raising.
        """
        env_path = os.getenv('SOFTWARE_TOOLS_MAP_PATH')
        env_url = os.getenv('SOFTWARE_TOOLS_MAP_URL')
        repo_default = Path(__file__).parent.parent / 'config' / 'tech_tools_map.json'

        # Attempt path first
        if env_path:
            p = Path(env_path)
            if p.is_file():
                try:
                    with p.open('r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, dict):
                        return {k: list(v) for k, v in data.items() if isinstance(v, (list, tuple))}
                except Exception as e:
                    logging.warning(f"Failed loading tools map from SOFTWARE_TOOLS_MAP_PATH={env_path}: {e}")

        # Attempt URL next
        if env_url and (req := requests):
            try:
                parsed = urlparse(env_url)
                if parsed.scheme in ('http', 'https'):
                    resp = req.get(env_url, timeout=5)
                    if resp.status_code == 200:
                        data = resp.json()
                        if isinstance(data, dict):
                            return {k: list(v) for k, v in data.items() if isinstance(v, (list, tuple))}
                    else:
                        logging.warning(f"Non-200 status fetching tools map URL {env_url}: {resp.status_code}")
            except Exception as e:
                logging.warning(f"Failed loading tools map from SOFTWARE_TOOLS_MAP_URL={env_url}: {e}")
        elif env_url and not requests:
            logging.warning("SOFTWARE_TOOLS_MAP_URL provided but 'requests' not installed; skipping remote fetch.")

        # Repo default file
        if repo_default.is_file():
            try:
                with repo_default.open('r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict):
                    return {k: list(v) for k, v in data.items() if isinstance(v, (list, tuple))}
            except Exception as e:
                logging.warning(f"Failed loading repo default tech_tools_map.json: {e}")

        # Fallback
        return self._default_tools_map()

    def reload_tools_map(self) -> None:
        """Public method to reload the tools mapping at runtime."""
        self.tech_tools_map = self._load_tools_map()
        logging.info("tech_tools_map reloaded; entries=%d", len(self.tech_tools_map))

    def _load_models(self) -> None:
        try:
            self.vectorizer = joblib.load(os.path.join(self.model_dir, 'tfidf_vectorizer.joblib'))
            self.software_classifier = joblib.load(os.path.join(self.model_dir, 'software_classifier.joblib'))
            self.tech_classifier = joblib.load(os.path.join(self.model_dir, 'tech_multilabel_classifier.joblib'))
            self.loc_regressor = joblib.load(os.path.join(self.model_dir, 'loc_regressor.joblib'))
            self.time_regressor = joblib.load(os.path.join(self.model_dir, 'time_regressor.joblib'))
            # optional score model; if missing, we'll compute score heuristically from LOC/tech
            score_path = os.path.join(self.model_dir, 'score_regressor.joblib')
            self.score_regressor = joblib.load(score_path) if os.path.isfile(score_path) else None
        except FileNotFoundError as e:
            raise RuntimeError(f"Software models not found in {self.model_dir}. Run train_software_models.py first.") from e

    def _predict_is_software(self, text: str) -> float:
        X = self.vectorizer.transform([text])
        if hasattr(self.software_classifier, 'predict_proba'):
            proba = self.software_classifier.predict_proba(X)[0][-1]
        else:
            # Some linear models may not expose predict_proba; use decision_function as proxy
            dec = self.software_classifier.decision_function(X)
            proba = 1.0 / (1.0 + np.exp(-float(dec)))
        return float(proba)

    def _predict_technologies(self, text: str) -> List[str]:
        X = self.vectorizer.transform([text])
        if hasattr(self.tech_classifier, 'predict_proba'):
            probs = self.tech_classifier.predict_proba(X)[0]
            tech_labels = getattr(self.tech_classifier, 'classes_', None)
            if tech_labels is None:
                return []
            # Lower threshold for multi-label tech detection (was 0.5, now 0.15)
            # This allows detection of technologies mentioned in text even with lower confidence
            return [str(tech_labels[i]) for i, p in enumerate(probs) if p >= 0.15]
        # Fallback to binary predictions
        preds = self.tech_classifier.predict(X)[0]
        tech_labels = getattr(self.tech_classifier, 'classes_', None)
        return [str(tech_labels[i]) for i, v in enumerate(preds) if v == 1]

    def _predict_loc_and_time(self, text: str) -> tuple[float, float]:
        X = self.vectorizer.transform([text])
        loc = float(self.loc_regressor.predict(X)[0])
        hours = float(self.time_regressor.predict(X)[0])
        # Keep sane bounds
        loc = max(20.0, min(loc, 500_000.0))
        hours = max(1.0, min(hours, 10_000.0))
        return loc, hours

    def _compute_complexity(self, text: str, technologies: List[str], loc: float, hours: float) -> float:
        if self.score_regressor is not None:
            X = self.vectorizer.transform([text])
            score = float(self.score_regressor.predict(X)[0])
            return max(10.0, min(score, 200.0))
        # Heuristic: combine log(LOC), log(hours), and tech count
        tech_weight = 6.0
        loc_term = 10.0 * math.log10(max(50.0, loc))
        time_term = 8.0 * math.log10(max(2.0, hours))
        tech_term = tech_weight * math.sqrt(len(technologies) + 1)
        base = loc_term + time_term + tech_term
        return float(max(10.0, min(base, 200.0)))

    def _ai_accelerated_time(self, technologies: List[str], hours: float) -> float:
        # Rough multipliers: CRUD web/api benefits more than deep ML/systems
        lower = {'react', 'nextjs', 'vue', 'angular', 'node', 'python_fastapi', 'python_django', 'flask'}
        higher = {'ai_llm', 'ml', 'cv', 'nlp'}
        factor = 0.5  # default 50% time with AI assistance
        if any(t in technologies for t in lower):
            factor = 0.35
        if any(t in technologies for t in higher):
            factor = max(factor, 0.6)
        return float(max(0.5, hours * factor))

    def _required_tools(self, technologies: List[str]) -> List[str]:
        tools: List[str] = []
        for t in technologies:
            tools.extend(self.tech_tools_map.get(t, []))
        # Deduplicate while preserving order
        seen = set()
        result = []
        for x in tools:
            if x not in seen:
                result.append(x)
                seen.add(x)
        return result

    def analyze_text(self, text: str) -> Dict[str, Any]:
        if not text or not text.strip():
            return {"error": "Empty requirement text", "ok": False}

        software_proba = self._predict_is_software(text)
        if software_proba < 0.60:
            # Not a software requirement with sufficient confidence
            return {
                "ok": False,
                "error": "Only computer/software jobs are supported for complexity scoring.",
                "software_probability": round(software_proba, 2)
            }

        technologies = self._predict_technologies(text)
        loc, hours = self._predict_loc_and_time(text)
        complexity_score = self._compute_complexity(text, technologies, loc, hours)
        ai_hours = self._ai_accelerated_time(technologies, hours)
        required_tools = self._required_tools(technologies)

        return {
            "ok": True,
            "software_probability": round(software_proba, 2),
            "complexity_score": round(complexity_score, 2),
            "predicted_loc": int(loc),
            "predicted_hours_manual": round(hours, 2),
            "predicted_hours_with_ai": round(ai_hours, 2),
            "technologies": technologies,
            "required_tools": required_tools,
            "assumptions": {
                "ai_speedup_note": "AI assistance assumed to speed up common CRUD and boilerplate tasks more than specialized ML or low-level systems work.",
                "loc_basis": "LOC estimate learned from examples; upper/lower bounds applied for sanity."
            }
        }
